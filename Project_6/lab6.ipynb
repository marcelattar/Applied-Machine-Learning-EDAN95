{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your implementation task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Implement the EM-algorithm to find a Gaussian NBC for the digits dataset from SciKitLearn (you can of course also use the MNIST_Light set from Lab 5, but for initial tests the digits data set is more convenient, since it is smaller in various aspects). You may assume (conditional) independence between the attributes, i.e., the covariances can be assumed to be simply the variances over each attribute. Split the data set in 70% training and 30% test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn Digits <a name='sklearn1'></a>\n",
    "Split the data set in 70% training and 30% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X, y = load_digits(n_class=10, return_X_y=True)\n",
    "# I have to do this to get reasonable results\n",
    "X= min_max_scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"E_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"M_step.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "def EM_algorithm(X, k_classes, N=200,  eps=5e-2):\n",
    "    \n",
    "    def E_step(X, k_classes, mu, sig, prior):\n",
    "        r = np.zeros([len(X), k_classes]) # Shape 1257, 10\n",
    "        for i, xi in enumerate(X):\n",
    "            # I used the predefined norm.pdf function from scipy\n",
    "            num = np.prod([norm.pdf(xi, mu[kcl], np.sqrt(sig[kcl])) for kcl in range(k_classes)], axis=1)\n",
    "            # Here I just multiply by the prior, pi_k\n",
    "            num = [prior[kcl]*num[kcl] for kcl in range(k_classes)]\n",
    "            den = np.sum(num)\n",
    "            r[i, :] = num/den            \n",
    "        return r \n",
    "\n",
    "    def M_step(X, r):\n",
    "        N, k_classes = r.shape\n",
    "        # This is just pi_k^t from the formula above but for all k's, i.e. just pi^t\n",
    "        prior = {kcl:np.sum(r[:, kcl])/N for kcl in range(k_classes)}\n",
    "        mu = {}\n",
    "        sig = {}\n",
    "        \n",
    "        for kcl in range(k_classes):\n",
    "            mu[kcl] = np.sum([r[i, kcl]*xi for i, xi in enumerate(X)], axis=0)/np.sum(r[:, kcl])\n",
    "            # I take the diag since we only have a variance (no covariance since independet variables)\n",
    "            sig[kcl] = np.sum([r[i, kcl]*np.diag(np.outer(xi, xi)) for i, xi in enumerate(X)], axis= 0)/np.sum(r[:, kcl]) - np.diag(np.outer(mu[kcl], mu[kcl])) + eps\n",
    "        return mu, sig, prior\n",
    "    \n",
    "    \n",
    "    # Initial values\n",
    "    mu = {kcl:np.random.uniform(1, size=X[0].size) for kcl in range(k_classes)}\n",
    "    sig = {kcl:np.random.uniform(0.5, size=X[0].size) for kcl in range(k_classes)}\n",
    "    prior = {kcl:1/k_classes for kcl in range(k_classes)} # This is pi_k in the notes                                                    \n",
    "    \n",
    "    # Here I iterate the E and M step a fixed amount of times (not necessarily until convergence)\n",
    "    for iteration in range(N):\n",
    "        r = E_step(X_train, k_classes, mu, sig, prior)\n",
    "        mu, sig, prior = M_step(X_train, r)\n",
    "        \n",
    "    class GNB_classifier:\n",
    "        def __init__(self, mu, sig, prior, k_classes, eps):\n",
    "            self.mu = mu\n",
    "            self.sig = sig\n",
    "            self.prior = prior\n",
    "            self.eps = eps\n",
    "            self.classes = k_classes\n",
    "        \n",
    "        \n",
    "        def predict(self, X):\n",
    "            # This is all taken from lab 5 from the Gaussian Naive Bayesian Classifier (GNB) class\n",
    "            y_pred = []\n",
    "            for x in X:\n",
    "                prob = [self._posterior(x, kcl) for kcl in range(self.classes)]\n",
    "                y_pred.append(np.argmax(prob))\n",
    "            return np.asarray(y_pred)\n",
    "    \n",
    "    \n",
    "        def _posterior(self, x, ci):\n",
    "            return self.prior[ci]*np.prod([norm.pdf(x[i], self.mu[ci][i], self.sig[ci][i] + self.eps) for i in range(len(x))])\n",
    "    \n",
    "    return GNB_classifier(mu, sig, prior, k_classes, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Fuck this\n",
    "class EM_gNBC:\n",
    "\n",
    "    def __init__(self, num_classes, shape): # shape should be a tuple\n",
    "        self.num_classes = num_classes\n",
    "        self.gaussian = {cl: {'mean': np.random.uniform(low=0, high=1, size=shape),\n",
    "                              'var': np.random.uniform(low=0, high=1, size=shape)} for cl in range(num_classes)}\n",
    "        \n",
    "        self.prior = {cl: np.random.uniform(low=0, high=1, size=1) for cl in range(num_classes)} # This is pi_k in the notes                                                    \n",
    "    \n",
    "    def E_step(self, X_train):\n",
    "        # Den h√§r borde jag nog flytta till __init__()\n",
    "        r = np.zeros((X_train.shape[0], self.num_classes)) # Shape 1257, 10\n",
    "        \n",
    "        for index, x in enumerate(X_train):\n",
    "            num = np.prod([norm.pdf(x, self.gaussian[k]['mean'], np.sqrt(self.gaussian[k]['var'])) \n",
    "                                for k in range(self.num_classes)], axis= 1)\n",
    "            num = [self.prior[k]*num[k] for k in range(num_classes)]\n",
    "            num = np.asarray(num)\n",
    "            print(num.shape)\n",
    "            den = np.sum(num)\n",
    "            print(den.shape)\n",
    "            a = num/den\n",
    "            print(a.shape)\n",
    "            r[index,:] = a\n",
    "        return r\n",
    "    \n",
    "    def M_step(self, X_train, ri):\n",
    "        #r = np.sum(ri)\n",
    "        \n",
    "        return none\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " r = np.zeros((len(X_train), self.num_classes))\n",
    "            \n",
    "            for index,x in enumerate(X_train):\n",
    "                num = np.prod([norm.pdf(x, self.gaussian[k]['mean'], np.sqrt(self.gaussian[k]['var']))\n",
    "                                    for k in range(self.num_classes)], axis = 1)\n",
    "                num = [self.priors[k]*num[k] for k in range(self.num_classes)]\n",
    "                den = np.sum(num)\n",
    "                r[index,:] = num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64)\n",
      "()\n",
      "(10, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,64) into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-4ff81ea3aedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_gNBC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-4dea52741b0b>\u001b[0m in \u001b[0;36mE_step\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,64) into shape (10)"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "shape = X_train.shape\n",
    "model = EM_gNBC(num_classes, shape)\n",
    "\n",
    "r = model.E_step(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 val: [ 0.  0.  5. 13. 13.  8.  0.  0.  0.  0. 16. 11. 13. 16.  6.  0.  0.  1.\n",
      " 16.  5.  2. 14.  9.  0.  0.  0.  9. 16. 16. 15.  0.  0.  0.  0. 10. 16.\n",
      " 14. 14.  0.  0.  0.  5. 15.  4.  0. 16.  6.  0.  0.  6. 14.  7.  6. 16.\n",
      "  4.  0.  0.  0.  7. 15. 16. 10.  0.  0.]\n",
      "<class 'numpy.ndarray'>\n",
      "index 1 val: [ 0.  0.  3. 14. 16. 14.  0.  0.  0.  0. 13. 13. 13. 16.  2.  0.  0.  0.\n",
      "  1.  0.  9. 15.  0.  0.  0.  0.  9. 12. 15. 16. 10.  0.  0.  4. 16. 16.\n",
      " 16. 11.  3.  0.  0.  0.  4.  9. 14.  2.  0.  0.  0.  0.  2. 15.  9.  0.\n",
      "  0.  0.  0.  0.  4. 13.  1.  0.  0.  0.]\n",
      "<class 'numpy.ndarray'>\n",
      "index 2 val: [ 0.  0.  5. 13.  2.  0.  0.  0.  0.  0.  4. 16.  7.  0.  0.  0.  0.  0.\n",
      "  4. 16.  4.  0.  0.  0.  0.  0.  4. 16.  6.  0.  0.  0.  0.  0.  9. 16.\n",
      " 10.  0.  0.  0.  0.  0.  2. 11. 15.  1.  0.  0.  0.  0. 10. 13. 16. 15.\n",
      " 16.  9.  0.  0.  3. 12. 16. 16. 11.  2.]\n",
      "<class 'numpy.ndarray'>\n",
      "index 3 val: [ 0.  0.  0.  6. 16.  2.  0.  0.  0.  0.  2. 15. 15.  0.  0.  0.  0.  0.\n",
      " 15. 16.  3.  2.  3.  0.  0.  7. 16.  7.  3. 15. 11.  0.  0.  7. 16. 14.\n",
      " 14. 16.  5.  0.  0.  1.  7. 12. 16. 10.  0.  0.  0.  0.  0.  7. 16.  4.\n",
      "  0.  0.  0.  0.  0. 10. 15.  0.  0.  0.]\n",
      "<class 'numpy.ndarray'>\n",
      "index 4 val: [ 0.  0.  0.  7. 15.  0.  0.  0.  0.  0.  6. 15.  8.  0.  0.  0.  0.  0.\n",
      " 13.  9.  0.  0.  0.  0.  0.  2. 16.  5.  4.  1.  0.  0.  0.  5. 16. 16.\n",
      " 16. 12.  3.  0.  0.  1. 15.  4.  1.  8. 12.  0.  0.  0.  8. 14.  5.  5.\n",
      " 15.  0.  0.  0.  0.  6. 16. 16. 11.  0.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = {cl: [1, 2, 3] for cl in range(10)}\n",
    "test[0]\n",
    "\n",
    "#shape = (5,2)\n",
    "#a = np.random.uniform(low=0, high=1, size=shape)\n",
    "\n",
    "#print(a)\n",
    "np.sqrt(np.pi)\n",
    "\n",
    "\n",
    "for index, val in enumerate(X_train):\n",
    "    print('index', index,'val:', val)\n",
    "    if i == 4:\n",
    "        break\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the result of the EM-algorithm (the found distribution parameters) to cluster the training data (essentially, using the resulting classifier to do a prediction over the training data). Produce a confusion matrix over the known labels for the training data and your EM-generated clusters. What do you see?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Homogeneity: score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling*\n",
    "\n",
    "*Completeness: score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling*\n",
    "\n",
    "*V_measure: harmonic mean of the first two*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score:  0.7426691658751972\n",
      "Completeness Score:  0.7661825944183708\n",
      "V-measure:  0.7542426675422047\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "gnb_clf = EM_algorithm(X_train, k_classes=10, N=200)\n",
    "gnb_pred = gnb_clf.predict(X_test)\n",
    "measure = metrics.homogeneity_completeness_v_measure(y_test, gnb_pred)\n",
    "\n",
    "print(\"Homogeneity Score: \", measure[0])\n",
    "print(\"Completeness Score: \", measure[1])\n",
    "print(\"V-measure: \", measure[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If necessary, find a way to \"repair\" the cluster assignments so that you can do a prediction run over the test data, from which you can compare the results with your earlier implementation of the Gaussian NBC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report GNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00        47\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       0.95      0.95      0.95        60\n",
      "           5       0.00      0.00      0.00        66\n",
      "           6       0.00      0.00      0.00        53\n",
      "           7       0.06      0.05      0.06        55\n",
      "           8       0.00      0.00      0.00        43\n",
      "           9       0.05      0.03      0.04        59\n",
      "\n",
      "    accuracy                           0.21       540\n",
      "   macro avg       0.21      0.20      0.20       540\n",
      "weighted avg       0.22      0.21      0.21       540\n",
      "\n",
      "\n",
      "Confusion matrix GNB:\n",
      "[[50  0  1  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 13  0 27 10  0]\n",
      " [ 0  0  0  0  0  0  0  0 41  6]\n",
      " [ 0 42  0  0  0  0  2  2  0  8]\n",
      " [ 0  0  0  0 57  1  2  0  0  0]\n",
      " [ 0 20 44  1  1  0  0  0  0  0]\n",
      " [ 0  0  0 53  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 52  3  0  0]\n",
      " [ 0  1  1  0  0  0  0 20  0 21]\n",
      " [ 0 47  1  0  0  5  3  1  0  2]]\n"
     ]
    }
   ],
   "source": [
    "# I definitevly need to repair my cluster assignment judging from the results.\n",
    "print(\"Classification report GNB:\\n%s\\n\"\n",
    "      % (metrics.classification_report(y_test, gnb_pred)))\n",
    "print(\"Confusion matrix GNB:\\n%s\" % metrics.confusion_matrix(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(X_train, y_train, y_pred):\n",
    "    k_classes = list(set(y_train))\n",
    "    c_true = {}\n",
    "    c_pred = {}\n",
    "    for kcl in k_classes:\n",
    "        c_true[kcl] = np.mean([X for i, X in enumerate(X_train) if y_train[i] == kcl], axis=0)\n",
    "        c_pred[kcl] = np.mean([X for i, X in enumerate(X_train) if y_pred[i] == kcl], axis=0)\n",
    "\n",
    "    pred2true = {}\n",
    "    for kcl in k_classes:\n",
    "        pred2true[kcl] = np.argmin([np.linalg.norm(c_pred[kcl] - c_true_v) for c_true_v in c_true.values()])\n",
    "    \n",
    "    y_new = []\n",
    "    for y in y_pred:\n",
    "        y_new.append(pred2true[y])\n",
    "    return np.asarray(y_new)\n",
    "\n",
    "\n",
    "def repair_ind(X_train, y_train, y_pred):\n",
    "    k_classes = list(set(y_train))\n",
    "    pred2true = {}\n",
    "    for kcl in k_classes:\n",
    "        indices = [i for i, x in enumerate(X_train) if y_pred[i] == kcl]\n",
    "        unique, counts= np.unique(y_train[indices], return_counts=True)\n",
    "        pred2true[kcl] = unique[np.argmax(counts)]\n",
    "        \n",
    "    y_new = []\n",
    "    for y in y_pred:\n",
    "        y_new.append(pred2true[y])\n",
    "    return np.asarray(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score:  0.7316801857859325\n",
      "Completeness Score:  0.7818801149280263\n",
      "V-measure:  0.7559476652274862\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        53\n",
      "           1       0.56      0.80      0.66        50\n",
      "           2       0.80      0.87      0.84        47\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       0.95      0.95      0.95        60\n",
      "           5       0.94      0.67      0.78        66\n",
      "           6       0.98      1.00      0.99        53\n",
      "           7       0.88      0.95      0.91        55\n",
      "           8       0.57      0.49      0.53        43\n",
      "           9       0.43      0.80      0.56        59\n",
      "\n",
      "    accuracy                           0.75       540\n",
      "   macro avg       0.71      0.75      0.72       540\n",
      "weighted avg       0.72      0.75      0.72       540\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[50  0  0  0  2  1  0  0  0  0]\n",
      " [ 0 40 10  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  6  0]\n",
      " [ 0  2  0  0  0  0  0  2  8 42]\n",
      " [ 0  1  0  0 57  0  0  2  0  0]\n",
      " [ 0  0  0  0  1 44  1  0  0 20]\n",
      " [ 0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  3  0  0  0  0  0 52  0  0]\n",
      " [ 0 20  0  0  0  1  0  0 21  1]\n",
      " [ 0  6  0  0  0  1  0  3  2 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gnb_pred_fixed = repair_ind(X_test, y_test, gnb_pred)\n",
    "\n",
    "measure = metrics.homogeneity_completeness_v_measure(y_test, gnb_pred_fixed)\n",
    "\n",
    "print(\"Homogeneity Score: \", measure[0])\n",
    "print(\"Completeness Score: \", measure[1])\n",
    "print(\"V-measure: \", measure[2])\n",
    "print('\\n')\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(y_test, gnb_pred_fixed)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, gnb_pred_fixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I got reasonable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use now also the k-Means implementation from SciKitLearn and compare the results to yours (they should be similar at least in the sense that there are classes that are more clearly separated from the rest than others for both approaches). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score:  0.7561055338287734\n",
      "Completeness Score:  0.8081139384915079\n",
      "V-measure:  0.7812451278991431\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        53\n",
      "           1       0.77      0.80      0.78        50\n",
      "           2       0.79      0.87      0.83        47\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       0.96      0.90      0.93        60\n",
      "           5       0.94      0.68      0.79        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.87      1.00      0.93        55\n",
      "           8       0.82      0.86      0.84        43\n",
      "           9       0.41      0.81      0.55        59\n",
      "\n",
      "    accuracy                           0.79       540\n",
      "   macro avg       0.75      0.79      0.76       540\n",
      "weighted avg       0.75      0.79      0.76       540\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[52  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 40 10  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  4  2]\n",
      " [ 0  0  1  0  0  0  0  2  4 47]\n",
      " [ 0  4  0  0 54  0  0  2  0  0]\n",
      " [ 0  0  0  0  1 45  2  0  0 18]\n",
      " [ 1  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  3  0  0  0  1  0  0 37  2]\n",
      " [ 0  5  0  0  0  2  0  4  0 48]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km_clf = KMeans(n_clusters=10, random_state=42).fit(X_train)\n",
    "km_pred = km_clf.predict(X_test)\n",
    "km_pred = repair(X_test, y_test, km_pred)\n",
    "\n",
    "measure = metrics.homogeneity_completeness_v_measure(y_test, km_pred)\n",
    "\n",
    "print(\"Homogeneity Score: \", measure[0])\n",
    "print(\"Completeness Score: \", measure[1])\n",
    "print(\"V-measure: \", measure[2])\n",
    "print('\\n')\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(y_test, km_pred)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
